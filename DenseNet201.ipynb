{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNiIHFSdzypV2eF/MFoud9D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ffatmanurggultekin/scoliosis-detection/blob/main/DenseNet201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elTmw0HCR3GG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBZ4TaiuR9Cz",
        "outputId": "2c05d258-1466-428e-94b5-29cf0a47321d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your data directories\n",
        "train_dir = '/content/drive/MyDrive/train_imadjust_sobel_diff_alpha0.5'\n",
        "val_dir = '/content/drive/MyDrive/validation_imadjust_sobel_diff_alpha0.5'\n",
        "test_dir = '/content/drive/MyDrive/test_imadjust_sobel_diff_alpha0.5'"
      ],
      "metadata": {
        "id": "0ooW_EiCR9nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and validation directories for cross-validation\n",
        "def gather_paths_and_labels(directory):\n",
        "    data = []\n",
        "    for label, class_name in enumerate(['Normal', 'Scol']):\n",
        "        class_dir = os.path.join(directory, class_name)\n",
        "        for file in os.listdir(class_dir):\n",
        "            data.append((os.path.join(class_dir, file), label))\n",
        "    return np.array(data)\n",
        "\n",
        "train_data = gather_paths_and_labels(train_dir)\n",
        "val_data = gather_paths_and_labels(val_dir)\n",
        "test_data = gather_paths_and_labels(test_dir)\n",
        "\n",
        "# Merge train and validation data for cross-validation\n",
        "train_val_data = np.concatenate((train_data, val_data))\n"
      ],
      "metadata": {
        "id": "ZslCTIt5SDxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Model creation function\n",
        "def create_densenet201_model():\n",
        "    base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False  # Freeze base model layers\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "bwsD2g5sTOyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validation function\n",
        "def run_cross_validation(data, n_splits=5, epochs=50, batch_size=32):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(data[:, 0], data[:, 1])):\n",
        "        print(f\"\\n=== Fold {fold + 1}/{n_splits} ===\")\n",
        "        train_files, val_files = data[train_idx], data[val_idx]\n",
        "\n",
        "        train_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
        "            pd.DataFrame({'filename': train_files[:, 0], 'class': train_files[:, 1]}),\n",
        "            x_col='filename', y_col='class',\n",
        "            target_size=(224, 224), batch_size=batch_size, class_mode='binary', shuffle=True\n",
        "        )\n",
        "\n",
        "        val_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
        "            pd.DataFrame({'filename': val_files[:, 0], 'class': val_files[:, 1]}),\n",
        "            x_col='filename', y_col='class',\n",
        "            target_size=(224, 224), batch_size=batch_size, class_mode='binary', shuffle=False\n",
        "        )\n",
        "\n",
        "        model = create_densenet201_model()\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "        model.fit(train_gen, validation_data=val_gen, epochs=epochs, callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "        val_labels = val_files[:, 1].astype(int)\n",
        "        val_preds = (model.predict(val_gen) > 0.5).astype(int).ravel()\n",
        "\n",
        "        accuracy_list.append((val_preds == val_labels).mean())\n",
        "        precision_list.append(precision_score(val_labels, val_preds))\n",
        "        recall_list.append(recall_score(val_labels, val_preds))\n",
        "        f1_list.append(f1_score(val_labels, val_preds))\n",
        "\n",
        "    print(\"\\n5-Fold Cross-Validation Results:\")\n",
        "    print(f\"Accuracy: {np.mean(accuracy_list):.4f} ± {np.std(accuracy_list):.4f}\")\n",
        "    print(f\"Precision: {np.mean(precision_list):.4f} ± {np.std(precision_list):.4f}\")\n",
        "    print(f\"Recall: {np.mean(recall_list):.4f} ± {np.std(recall_list):.4f}\")\n",
        "    print(f\"F1-Score: {np.mean(f1_list):.4f} ± {np.std(f1_list):.4f}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "4c5SaP5ic3oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Run cross-validation\n",
        "final_model = run_cross_validation(train_val_data)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6K4J39XTzMT",
        "outputId": "21cc7605-6606-4d25-db87-d04b0667f1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1/5 ===\n",
            "Found 171 validated image filenames belonging to 2 classes.\n",
            "Found 43 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - accuracy: 0.6955 - loss: 0.6359 - val_accuracy: 0.7209 - val_loss: 0.5458\n",
            "Epoch 2/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.6680 - loss: 0.6420 - val_accuracy: 0.7209 - val_loss: 0.4694\n",
            "Epoch 3/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.7561 - loss: 0.4745 - val_accuracy: 0.7209 - val_loss: 0.4150\n",
            "Epoch 4/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.8271 - loss: 0.3981 - val_accuracy: 0.8140 - val_loss: 0.3682\n",
            "Epoch 5/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.8364 - loss: 0.3533 - val_accuracy: 0.9302 - val_loss: 0.3301\n",
            "Epoch 6/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.8883 - loss: 0.3094 - val_accuracy: 0.9302 - val_loss: 0.3025\n",
            "Epoch 7/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9049 - loss: 0.2843 - val_accuracy: 0.9302 - val_loss: 0.2861\n",
            "Epoch 8/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9314 - loss: 0.2425 - val_accuracy: 0.9302 - val_loss: 0.2716\n",
            "Epoch 9/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - accuracy: 0.8527 - loss: 0.3091 - val_accuracy: 0.9302 - val_loss: 0.2530\n",
            "Epoch 10/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.8697 - loss: 0.2651 - val_accuracy: 0.9535 - val_loss: 0.2339\n",
            "Epoch 11/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.9684 - loss: 0.1989 - val_accuracy: 0.9535 - val_loss: 0.2255\n",
            "Epoch 12/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9448 - loss: 0.2056 - val_accuracy: 0.9535 - val_loss: 0.2159\n",
            "Epoch 13/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9166 - loss: 0.2170 - val_accuracy: 0.9535 - val_loss: 0.2073\n",
            "Epoch 14/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9637 - loss: 0.1777 - val_accuracy: 0.9535 - val_loss: 0.2021\n",
            "Epoch 15/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.9714 - loss: 0.1576 - val_accuracy: 0.9535 - val_loss: 0.1976\n",
            "Epoch 16/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9517 - loss: 0.1672 - val_accuracy: 0.9535 - val_loss: 0.1916\n",
            "Epoch 17/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.9342 - loss: 0.1771 - val_accuracy: 0.9535 - val_loss: 0.1759\n",
            "Epoch 18/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9334 - loss: 0.1681 - val_accuracy: 0.9535 - val_loss: 0.1694\n",
            "Epoch 19/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9788 - loss: 0.1286 - val_accuracy: 0.9535 - val_loss: 0.1695\n",
            "Epoch 20/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9670 - loss: 0.1316 - val_accuracy: 0.9535 - val_loss: 0.1691\n",
            "Epoch 21/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.9880 - loss: 0.1010 - val_accuracy: 0.9535 - val_loss: 0.1626\n",
            "Epoch 22/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9887 - loss: 0.1111 - val_accuracy: 0.9535 - val_loss: 0.1560\n",
            "Epoch 23/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.9904 - loss: 0.1000 - val_accuracy: 0.9535 - val_loss: 0.1545\n",
            "Epoch 24/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9585 - loss: 0.1261 - val_accuracy: 0.9535 - val_loss: 0.1500\n",
            "Epoch 25/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9760 - loss: 0.1299 - val_accuracy: 0.9535 - val_loss: 0.1538\n",
            "Epoch 26/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9813 - loss: 0.0853 - val_accuracy: 0.9535 - val_loss: 0.1578\n",
            "Epoch 27/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9880 - loss: 0.0975 - val_accuracy: 0.9535 - val_loss: 0.1525\n",
            "Epoch 28/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9640 - loss: 0.1296 - val_accuracy: 0.9535 - val_loss: 0.1514\n",
            "Epoch 29/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.9804 - loss: 0.1013 - val_accuracy: 0.9535 - val_loss: 0.1478\n",
            "Epoch 30/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9814 - loss: 0.0959 - val_accuracy: 0.9767 - val_loss: 0.1348\n",
            "Epoch 31/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9933 - loss: 0.0632 - val_accuracy: 0.9767 - val_loss: 0.1319\n",
            "Epoch 32/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9767 - loss: 0.0725 - val_accuracy: 0.9535 - val_loss: 0.1340\n",
            "Epoch 33/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9922 - loss: 0.0676 - val_accuracy: 0.9535 - val_loss: 0.1419\n",
            "Epoch 34/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9933 - loss: 0.0687 - val_accuracy: 0.9535 - val_loss: 0.1398\n",
            "Epoch 35/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9861 - loss: 0.0709 - val_accuracy: 0.9535 - val_loss: 0.1323\n",
            "Epoch 36/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.9928 - loss: 0.0615 - val_accuracy: 0.9767 - val_loss: 0.1274\n",
            "Epoch 37/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9686 - loss: 0.0755 - val_accuracy: 0.9767 - val_loss: 0.1256\n",
            "Epoch 38/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9945 - loss: 0.0583 - val_accuracy: 0.9767 - val_loss: 0.1278\n",
            "Epoch 39/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9767 - loss: 0.0699 - val_accuracy: 0.9767 - val_loss: 0.1289\n",
            "Epoch 40/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9949 - loss: 0.0497 - val_accuracy: 0.9535 - val_loss: 0.1288\n",
            "Epoch 41/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9945 - loss: 0.0650 - val_accuracy: 0.9767 - val_loss: 0.1237\n",
            "Epoch 42/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9904 - loss: 0.0614 - val_accuracy: 0.9767 - val_loss: 0.1177\n",
            "Epoch 43/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.9907 - loss: 0.0612 - val_accuracy: 0.9767 - val_loss: 0.1165\n",
            "Epoch 44/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9983 - loss: 0.0571 - val_accuracy: 0.9767 - val_loss: 0.1216\n",
            "Epoch 45/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9907 - loss: 0.0680 - val_accuracy: 0.9302 - val_loss: 0.1338\n",
            "Epoch 46/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9738 - loss: 0.0709 - val_accuracy: 0.9535 - val_loss: 0.1306\n",
            "Epoch 47/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9960 - loss: 0.0546 - val_accuracy: 0.9767 - val_loss: 0.1243\n",
            "Epoch 48/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9874 - loss: 0.0672 - val_accuracy: 0.9767 - val_loss: 0.1188\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14s/step\n",
            "\n",
            "=== Fold 2/5 ===\n",
            "Found 171 validated image filenames belonging to 2 classes.\n",
            "Found 43 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - accuracy: 0.5149 - loss: 0.7290 - val_accuracy: 0.7209 - val_loss: 0.5471\n",
            "Epoch 2/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.6955 - loss: 0.5624 - val_accuracy: 0.7209 - val_loss: 0.5317\n",
            "Epoch 3/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.7941 - loss: 0.4446 - val_accuracy: 0.7209 - val_loss: 0.4743\n",
            "Epoch 4/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.7976 - loss: 0.3911 - val_accuracy: 0.7907 - val_loss: 0.4081\n",
            "Epoch 5/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - accuracy: 0.8535 - loss: 0.3868 - val_accuracy: 0.8372 - val_loss: 0.3753\n",
            "Epoch 6/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.8434 - loss: 0.3511 - val_accuracy: 0.8605 - val_loss: 0.3480\n",
            "Epoch 7/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9081 - loss: 0.2994 - val_accuracy: 0.8837 - val_loss: 0.3260\n",
            "Epoch 8/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.8506 - loss: 0.3362 - val_accuracy: 0.9070 - val_loss: 0.3024\n",
            "Epoch 9/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - accuracy: 0.9032 - loss: 0.2624 - val_accuracy: 0.9070 - val_loss: 0.2817\n",
            "Epoch 10/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9001 - loss: 0.2872 - val_accuracy: 0.9302 - val_loss: 0.2670\n",
            "Epoch 11/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.9264 - loss: 0.2337 - val_accuracy: 0.9535 - val_loss: 0.2521\n",
            "Epoch 12/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9217 - loss: 0.2435 - val_accuracy: 0.9535 - val_loss: 0.2394\n",
            "Epoch 13/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.9515 - loss: 0.2041 - val_accuracy: 0.9535 - val_loss: 0.2308\n",
            "Epoch 14/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9678 - loss: 0.1910 - val_accuracy: 0.9535 - val_loss: 0.2201\n",
            "Epoch 15/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9399 - loss: 0.1860 - val_accuracy: 0.9535 - val_loss: 0.2090\n",
            "Epoch 16/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9530 - loss: 0.1976 - val_accuracy: 0.9535 - val_loss: 0.2009\n",
            "Epoch 17/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9451 - loss: 0.2084 - val_accuracy: 0.9535 - val_loss: 0.1928\n",
            "Epoch 18/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9329 - loss: 0.1909 - val_accuracy: 0.9535 - val_loss: 0.1883\n",
            "Epoch 19/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9864 - loss: 0.1223 - val_accuracy: 0.9535 - val_loss: 0.1863\n",
            "Epoch 20/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9749 - loss: 0.1500 - val_accuracy: 0.9535 - val_loss: 0.1795\n",
            "Epoch 21/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9891 - loss: 0.1279 - val_accuracy: 0.9535 - val_loss: 0.1714\n",
            "Epoch 22/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.9807 - loss: 0.1174 - val_accuracy: 0.9535 - val_loss: 0.1678\n",
            "Epoch 23/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9853 - loss: 0.1209 - val_accuracy: 0.9535 - val_loss: 0.1657\n",
            "Epoch 24/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9806 - loss: 0.1338 - val_accuracy: 0.9535 - val_loss: 0.1631\n",
            "Epoch 25/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9614 - loss: 0.1148 - val_accuracy: 0.9535 - val_loss: 0.1616\n",
            "Epoch 26/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9776 - loss: 0.1178 - val_accuracy: 0.9535 - val_loss: 0.1608\n",
            "Epoch 27/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9857 - loss: 0.1081 - val_accuracy: 0.9535 - val_loss: 0.1582\n",
            "Epoch 28/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9769 - loss: 0.1110 - val_accuracy: 0.9535 - val_loss: 0.1549\n",
            "Epoch 29/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9742 - loss: 0.0964 - val_accuracy: 0.9535 - val_loss: 0.1551\n",
            "Epoch 30/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9798 - loss: 0.0853 - val_accuracy: 0.9535 - val_loss: 0.1550\n",
            "Epoch 31/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9946 - loss: 0.0823 - val_accuracy: 0.9535 - val_loss: 0.1565\n",
            "Epoch 32/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.9983 - loss: 0.0748 - val_accuracy: 0.9535 - val_loss: 0.1547\n",
            "Epoch 33/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.9852 - loss: 0.0799 - val_accuracy: 0.9535 - val_loss: 0.1487\n",
            "Epoch 34/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9864 - loss: 0.0699 - val_accuracy: 0.9535 - val_loss: 0.1492\n",
            "Epoch 35/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9836 - loss: 0.0871 - val_accuracy: 0.9535 - val_loss: 0.1492\n",
            "Epoch 36/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9886 - loss: 0.0695 - val_accuracy: 0.9535 - val_loss: 0.1481\n",
            "Epoch 37/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0715 - val_accuracy: 0.9535 - val_loss: 0.1427\n",
            "Epoch 38/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 0.0602 - val_accuracy: 0.9535 - val_loss: 0.1413\n",
            "Epoch 39/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0752 - val_accuracy: 0.9535 - val_loss: 0.1422\n",
            "Epoch 40/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9947 - loss: 0.0635 - val_accuracy: 0.9535 - val_loss: 0.1442\n",
            "Epoch 41/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0561 - val_accuracy: 0.9535 - val_loss: 0.1469\n",
            "Epoch 42/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9983 - loss: 0.0573 - val_accuracy: 0.9535 - val_loss: 0.1531\n",
            "Epoch 43/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9918 - loss: 0.0582 - val_accuracy: 0.9535 - val_loss: 0.1512\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13s/step\n",
            "\n",
            "=== Fold 3/5 ===\n",
            "Found 171 validated image filenames belonging to 2 classes.\n",
            "Found 43 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 6s/step - accuracy: 0.4947 - loss: 0.8080 - val_accuracy: 0.6977 - val_loss: 0.5510\n",
            "Epoch 2/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.7218 - loss: 0.6006 - val_accuracy: 0.7209 - val_loss: 0.5340\n",
            "Epoch 3/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.7251 - loss: 0.5314 - val_accuracy: 0.7209 - val_loss: 0.4749\n",
            "Epoch 4/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.6962 - loss: 0.5033 - val_accuracy: 0.7442 - val_loss: 0.4047\n",
            "Epoch 5/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.8174 - loss: 0.3894 - val_accuracy: 0.8372 - val_loss: 0.3662\n",
            "Epoch 6/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.8324 - loss: 0.4005 - val_accuracy: 0.9302 - val_loss: 0.3353\n",
            "Epoch 7/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.8792 - loss: 0.3411 - val_accuracy: 0.9302 - val_loss: 0.3063\n",
            "Epoch 8/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.8181 - loss: 0.3573 - val_accuracy: 0.9302 - val_loss: 0.2823\n",
            "Epoch 9/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.8672 - loss: 0.3337 - val_accuracy: 0.9535 - val_loss: 0.2616\n",
            "Epoch 10/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.8998 - loss: 0.2857 - val_accuracy: 0.9535 - val_loss: 0.2431\n",
            "Epoch 11/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.8788 - loss: 0.2896 - val_accuracy: 0.9767 - val_loss: 0.2228\n",
            "Epoch 12/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.9109 - loss: 0.2493 - val_accuracy: 1.0000 - val_loss: 0.2072\n",
            "Epoch 13/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - accuracy: 0.9322 - loss: 0.2451 - val_accuracy: 1.0000 - val_loss: 0.1915\n",
            "Epoch 14/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9198 - loss: 0.2305 - val_accuracy: 1.0000 - val_loss: 0.1782\n",
            "Epoch 15/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.9455 - loss: 0.2137 - val_accuracy: 0.9767 - val_loss: 0.1678\n",
            "Epoch 16/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - accuracy: 0.9203 - loss: 0.2161 - val_accuracy: 1.0000 - val_loss: 0.1583\n",
            "Epoch 17/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.9332 - loss: 0.2166 - val_accuracy: 1.0000 - val_loss: 0.1502\n",
            "Epoch 18/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.9763 - loss: 0.1807 - val_accuracy: 1.0000 - val_loss: 0.1417\n",
            "Epoch 19/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.9532 - loss: 0.1756 - val_accuracy: 1.0000 - val_loss: 0.1367\n",
            "Epoch 20/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9560 - loss: 0.1460 - val_accuracy: 1.0000 - val_loss: 0.1339\n",
            "Epoch 21/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.9674 - loss: 0.1424 - val_accuracy: 1.0000 - val_loss: 0.1263\n",
            "Epoch 22/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.9646 - loss: 0.1532 - val_accuracy: 1.0000 - val_loss: 0.1168\n",
            "Epoch 23/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.9622 - loss: 0.1594 - val_accuracy: 1.0000 - val_loss: 0.1098\n",
            "Epoch 24/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9574 - loss: 0.1324 - val_accuracy: 1.0000 - val_loss: 0.1050\n",
            "Epoch 25/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9801 - loss: 0.1443 - val_accuracy: 1.0000 - val_loss: 0.1021\n",
            "Epoch 26/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.9635 - loss: 0.1570 - val_accuracy: 1.0000 - val_loss: 0.0995\n",
            "Epoch 27/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9856 - loss: 0.1323 - val_accuracy: 1.0000 - val_loss: 0.0950\n",
            "Epoch 28/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9684 - loss: 0.1144 - val_accuracy: 1.0000 - val_loss: 0.0911\n",
            "Epoch 29/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9797 - loss: 0.1182 - val_accuracy: 1.0000 - val_loss: 0.0880\n",
            "Epoch 30/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.9659 - loss: 0.1351 - val_accuracy: 1.0000 - val_loss: 0.0880\n",
            "Epoch 31/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - accuracy: 0.9752 - loss: 0.1050 - val_accuracy: 1.0000 - val_loss: 0.0839\n",
            "Epoch 32/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9882 - loss: 0.0971 - val_accuracy: 1.0000 - val_loss: 0.0804\n",
            "Epoch 33/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9794 - loss: 0.1073 - val_accuracy: 1.0000 - val_loss: 0.0795\n",
            "Epoch 34/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9630 - loss: 0.1158 - val_accuracy: 1.0000 - val_loss: 0.0792\n",
            "Epoch 35/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9853 - loss: 0.0869 - val_accuracy: 1.0000 - val_loss: 0.0765\n",
            "Epoch 36/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9828 - loss: 0.0983 - val_accuracy: 1.0000 - val_loss: 0.0767\n",
            "Epoch 37/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9956 - loss: 0.0985 - val_accuracy: 1.0000 - val_loss: 0.0714\n",
            "Epoch 38/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9640 - loss: 0.0967 - val_accuracy: 1.0000 - val_loss: 0.0696\n",
            "Epoch 39/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9863 - loss: 0.0908 - val_accuracy: 1.0000 - val_loss: 0.0659\n",
            "Epoch 40/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9767 - loss: 0.0850 - val_accuracy: 1.0000 - val_loss: 0.0646\n",
            "Epoch 41/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9878 - loss: 0.0789 - val_accuracy: 1.0000 - val_loss: 0.0631\n",
            "Epoch 42/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.9918 - loss: 0.0749 - val_accuracy: 1.0000 - val_loss: 0.0622\n",
            "Epoch 43/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9711 - loss: 0.0920 - val_accuracy: 1.0000 - val_loss: 0.0641\n",
            "Epoch 44/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.9935 - loss: 0.0642 - val_accuracy: 1.0000 - val_loss: 0.0617\n",
            "Epoch 45/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9778 - loss: 0.0772 - val_accuracy: 1.0000 - val_loss: 0.0572\n",
            "Epoch 46/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9907 - loss: 0.0791 - val_accuracy: 1.0000 - val_loss: 0.0560\n",
            "Epoch 47/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9720 - loss: 0.0894 - val_accuracy: 1.0000 - val_loss: 0.0578\n",
            "Epoch 48/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9831 - loss: 0.0596 - val_accuracy: 1.0000 - val_loss: 0.0553\n",
            "Epoch 49/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9852 - loss: 0.0615 - val_accuracy: 1.0000 - val_loss: 0.0541\n",
            "Epoch 50/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9776 - loss: 0.0763 - val_accuracy: 1.0000 - val_loss: 0.0520\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13s/step\n",
            "\n",
            "=== Fold 4/5 ===\n",
            "Found 171 validated image filenames belonging to 2 classes.\n",
            "Found 43 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - accuracy: 0.5997 - loss: 0.6544 - val_accuracy: 0.7209 - val_loss: 0.5051\n",
            "Epoch 2/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.7328 - loss: 0.4956 - val_accuracy: 0.7209 - val_loss: 0.4923\n",
            "Epoch 3/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.7412 - loss: 0.5224 - val_accuracy: 0.7442 - val_loss: 0.4105\n",
            "Epoch 4/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.8012 - loss: 0.3964 - val_accuracy: 0.9302 - val_loss: 0.3583\n",
            "Epoch 5/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - accuracy: 0.8470 - loss: 0.3939 - val_accuracy: 0.9535 - val_loss: 0.3301\n",
            "Epoch 6/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.8655 - loss: 0.3511 - val_accuracy: 0.9535 - val_loss: 0.3014\n",
            "Epoch 7/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9329 - loss: 0.2842 - val_accuracy: 0.9535 - val_loss: 0.2850\n",
            "Epoch 8/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9406 - loss: 0.2526 - val_accuracy: 0.9767 - val_loss: 0.2674\n",
            "Epoch 9/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.9624 - loss: 0.2168 - val_accuracy: 0.9767 - val_loss: 0.2477\n",
            "Epoch 10/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9361 - loss: 0.2486 - val_accuracy: 0.9767 - val_loss: 0.2282\n",
            "Epoch 11/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.9321 - loss: 0.2090 - val_accuracy: 0.9767 - val_loss: 0.2145\n",
            "Epoch 12/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.9473 - loss: 0.1986 - val_accuracy: 0.9535 - val_loss: 0.2044\n",
            "Epoch 13/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9680 - loss: 0.1788 - val_accuracy: 0.9535 - val_loss: 0.1935\n",
            "Epoch 14/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.9490 - loss: 0.1754 - val_accuracy: 0.9767 - val_loss: 0.1808\n",
            "Epoch 15/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.9306 - loss: 0.1997 - val_accuracy: 0.9767 - val_loss: 0.1728\n",
            "Epoch 16/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9572 - loss: 0.1577 - val_accuracy: 0.9767 - val_loss: 0.1622\n",
            "Epoch 17/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.9608 - loss: 0.1484 - val_accuracy: 0.9767 - val_loss: 0.1539\n",
            "Epoch 18/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9829 - loss: 0.1519 - val_accuracy: 0.9767 - val_loss: 0.1478\n",
            "Epoch 19/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.9564 - loss: 0.1392 - val_accuracy: 0.9767 - val_loss: 0.1419\n",
            "Epoch 20/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9636 - loss: 0.1270 - val_accuracy: 0.9767 - val_loss: 0.1362\n",
            "Epoch 21/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9571 - loss: 0.1351 - val_accuracy: 0.9767 - val_loss: 0.1305\n",
            "Epoch 22/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9599 - loss: 0.1273 - val_accuracy: 0.9767 - val_loss: 0.1253\n",
            "Epoch 23/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.9556 - loss: 0.1515 - val_accuracy: 0.9767 - val_loss: 0.1213\n",
            "Epoch 24/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.9579 - loss: 0.1360 - val_accuracy: 0.9767 - val_loss: 0.1186\n",
            "Epoch 25/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - accuracy: 0.9884 - loss: 0.0926 - val_accuracy: 1.0000 - val_loss: 0.1142\n",
            "Epoch 26/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9727 - loss: 0.0914 - val_accuracy: 0.9767 - val_loss: 0.1102\n",
            "Epoch 27/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.9636 - loss: 0.1360 - val_accuracy: 1.0000 - val_loss: 0.1079\n",
            "Epoch 28/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9756 - loss: 0.0977 - val_accuracy: 1.0000 - val_loss: 0.1052\n",
            "Epoch 29/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9752 - loss: 0.0992 - val_accuracy: 0.9767 - val_loss: 0.1022\n",
            "Epoch 30/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9661 - loss: 0.1027 - val_accuracy: 0.9767 - val_loss: 0.0996\n",
            "Epoch 31/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9760 - loss: 0.1313 - val_accuracy: 1.0000 - val_loss: 0.0975\n",
            "Epoch 32/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.9725 - loss: 0.1082 - val_accuracy: 1.0000 - val_loss: 0.0941\n",
            "Epoch 33/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9830 - loss: 0.0803 - val_accuracy: 1.0000 - val_loss: 0.0912\n",
            "Epoch 34/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.9891 - loss: 0.0933 - val_accuracy: 1.0000 - val_loss: 0.0894\n",
            "Epoch 35/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9660 - loss: 0.0930 - val_accuracy: 1.0000 - val_loss: 0.0883\n",
            "Epoch 36/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9906 - loss: 0.0652 - val_accuracy: 1.0000 - val_loss: 0.0876\n",
            "Epoch 37/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.9752 - loss: 0.0734 - val_accuracy: 1.0000 - val_loss: 0.0853\n",
            "Epoch 38/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9907 - loss: 0.0691 - val_accuracy: 1.0000 - val_loss: 0.0835\n",
            "Epoch 39/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.9875 - loss: 0.0686 - val_accuracy: 1.0000 - val_loss: 0.0819\n",
            "Epoch 40/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9609 - loss: 0.1043 - val_accuracy: 1.0000 - val_loss: 0.0804\n",
            "Epoch 41/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9856 - loss: 0.0735 - val_accuracy: 1.0000 - val_loss: 0.0783\n",
            "Epoch 42/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9922 - loss: 0.0677 - val_accuracy: 1.0000 - val_loss: 0.0776\n",
            "Epoch 43/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9711 - loss: 0.0787 - val_accuracy: 0.9767 - val_loss: 0.0779\n",
            "Epoch 44/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9938 - loss: 0.0678 - val_accuracy: 0.9767 - val_loss: 0.0758\n",
            "Epoch 45/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9782 - loss: 0.0731 - val_accuracy: 1.0000 - val_loss: 0.0741\n",
            "Epoch 46/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9886 - loss: 0.0541 - val_accuracy: 1.0000 - val_loss: 0.0731\n",
            "Epoch 47/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9935 - loss: 0.0473 - val_accuracy: 0.9767 - val_loss: 0.0726\n",
            "Epoch 48/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9948 - loss: 0.0636 - val_accuracy: 0.9767 - val_loss: 0.0738\n",
            "Epoch 49/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9782 - loss: 0.0602 - val_accuracy: 0.9767 - val_loss: 0.0709\n",
            "Epoch 50/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9947 - loss: 0.0514 - val_accuracy: 0.9767 - val_loss: 0.0701\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 14s/step\n",
            "\n",
            "=== Fold 5/5 ===\n",
            "Found 172 validated image filenames belonging to 2 classes.\n",
            "Found 42 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - accuracy: 0.6037 - loss: 0.6791 - val_accuracy: 0.7381 - val_loss: 0.4681\n",
            "Epoch 2/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.6900 - loss: 0.5530 - val_accuracy: 0.7381 - val_loss: 0.4245\n",
            "Epoch 3/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.7327 - loss: 0.5148 - val_accuracy: 0.7619 - val_loss: 0.3749\n",
            "Epoch 4/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.8159 - loss: 0.4152 - val_accuracy: 0.8810 - val_loss: 0.3434\n",
            "Epoch 5/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.8779 - loss: 0.3690 - val_accuracy: 0.8810 - val_loss: 0.3201\n",
            "Epoch 6/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.8696 - loss: 0.3337 - val_accuracy: 0.8571 - val_loss: 0.2977\n",
            "Epoch 7/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.8879 - loss: 0.2953 - val_accuracy: 0.9048 - val_loss: 0.2790\n",
            "Epoch 8/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.8777 - loss: 0.3117 - val_accuracy: 0.8571 - val_loss: 0.2653\n",
            "Epoch 9/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9126 - loss: 0.2857 - val_accuracy: 0.9048 - val_loss: 0.2531\n",
            "Epoch 10/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9311 - loss: 0.2427 - val_accuracy: 0.9286 - val_loss: 0.2431\n",
            "Epoch 11/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9411 - loss: 0.2014 - val_accuracy: 0.9048 - val_loss: 0.2360\n",
            "Epoch 12/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9248 - loss: 0.2178 - val_accuracy: 0.9286 - val_loss: 0.2275\n",
            "Epoch 13/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.9577 - loss: 0.1914 - val_accuracy: 0.9048 - val_loss: 0.2208\n",
            "Epoch 14/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9756 - loss: 0.1724 - val_accuracy: 0.9286 - val_loss: 0.2129\n",
            "Epoch 15/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9842 - loss: 0.1503 - val_accuracy: 0.9286 - val_loss: 0.2071\n",
            "Epoch 16/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9731 - loss: 0.1834 - val_accuracy: 0.9524 - val_loss: 0.1999\n",
            "Epoch 17/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.9535 - loss: 0.1746 - val_accuracy: 0.9286 - val_loss: 0.1947\n",
            "Epoch 18/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9973 - loss: 0.1442 - val_accuracy: 0.9524 - val_loss: 0.1876\n",
            "Epoch 19/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9542 - loss: 0.1558 - val_accuracy: 0.9524 - val_loss: 0.1856\n",
            "Epoch 20/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9781 - loss: 0.1116 - val_accuracy: 0.9286 - val_loss: 0.1858\n",
            "Epoch 21/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9756 - loss: 0.1159 - val_accuracy: 0.9286 - val_loss: 0.1797\n",
            "Epoch 22/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.9840 - loss: 0.1096 - val_accuracy: 0.9524 - val_loss: 0.1734\n",
            "Epoch 23/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9963 - loss: 0.0854 - val_accuracy: 0.9524 - val_loss: 0.1695\n",
            "Epoch 24/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9809 - loss: 0.1220 - val_accuracy: 0.9524 - val_loss: 0.1660\n",
            "Epoch 25/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.9912 - loss: 0.0864 - val_accuracy: 0.9524 - val_loss: 0.1636\n",
            "Epoch 26/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9957 - loss: 0.0945 - val_accuracy: 0.9524 - val_loss: 0.1599\n",
            "Epoch 27/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9930 - loss: 0.0796 - val_accuracy: 0.9524 - val_loss: 0.1573\n",
            "Epoch 28/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9930 - loss: 0.0895 - val_accuracy: 0.9524 - val_loss: 0.1568\n",
            "Epoch 29/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9983 - loss: 0.0658 - val_accuracy: 0.9524 - val_loss: 0.1599\n",
            "Epoch 30/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9870 - loss: 0.0750 - val_accuracy: 0.9524 - val_loss: 0.1563\n",
            "Epoch 31/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9728 - loss: 0.0971 - val_accuracy: 0.9524 - val_loss: 0.1502\n",
            "Epoch 32/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9914 - loss: 0.0702 - val_accuracy: 0.9524 - val_loss: 0.1478\n",
            "Epoch 33/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9918 - loss: 0.0693 - val_accuracy: 0.9524 - val_loss: 0.1472\n",
            "Epoch 34/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9973 - loss: 0.0646 - val_accuracy: 0.9524 - val_loss: 0.1452\n",
            "Epoch 35/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.9689 - loss: 0.0876 - val_accuracy: 0.9524 - val_loss: 0.1430\n",
            "Epoch 36/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.9874 - loss: 0.0752 - val_accuracy: 0.9524 - val_loss: 0.1401\n",
            "Epoch 37/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.9773 - loss: 0.0783 - val_accuracy: 0.9524 - val_loss: 0.1395\n",
            "Epoch 38/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9973 - loss: 0.0590 - val_accuracy: 0.9524 - val_loss: 0.1398\n",
            "Epoch 39/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9973 - loss: 0.0599 - val_accuracy: 0.9524 - val_loss: 0.1410\n",
            "Epoch 40/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0547 - val_accuracy: 0.9524 - val_loss: 0.1405\n",
            "Epoch 41/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9887 - loss: 0.0570 - val_accuracy: 0.9524 - val_loss: 0.1370\n",
            "Epoch 42/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9744 - loss: 0.0720 - val_accuracy: 0.9524 - val_loss: 0.1338\n",
            "Epoch 43/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.9933 - loss: 0.0465 - val_accuracy: 0.9524 - val_loss: 0.1329\n",
            "Epoch 44/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0510 - val_accuracy: 0.9524 - val_loss: 0.1330\n",
            "Epoch 45/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - accuracy: 0.9919 - loss: 0.0442 - val_accuracy: 0.9524 - val_loss: 0.1325\n",
            "Epoch 46/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9892 - loss: 0.0463 - val_accuracy: 0.9286 - val_loss: 0.1317\n",
            "Epoch 47/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9963 - loss: 0.0453 - val_accuracy: 0.9524 - val_loss: 0.1328\n",
            "Epoch 48/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9827 - loss: 0.0578 - val_accuracy: 0.9524 - val_loss: 0.1320\n",
            "Epoch 49/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9948 - loss: 0.0415 - val_accuracy: 0.9524 - val_loss: 0.1300\n",
            "Epoch 50/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.9947 - loss: 0.0577 - val_accuracy: 0.9524 - val_loss: 0.1286\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13s/step\n",
            "\n",
            "5-Fold Cross-Validation Results:\n",
            "Accuracy: 0.9719 ± 0.0176\n",
            "Precision: 0.9695 ± 0.0271\n",
            "Recall: 0.9935 ± 0.0129\n",
            "F1-Score: 0.9810 ± 0.0116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set evaluation\n",
        "test_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
        "    pd.DataFrame({'filename': test_data[:, 0], 'class': test_data[:, 1]}),\n",
        "    x_col='filename', y_col='class',\n",
        "    target_size=(224, 224), batch_size=32, class_mode='binary', shuffle=False\n",
        ")\n",
        "\n",
        "test_labels = test_data[:, 1].astype(int)\n",
        "test_preds = (final_model.predict(test_gen) > 0.5).astype(int).ravel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbQp5s2ccHFD",
        "outputId": "24a15fbf-a18e-4aab-e598-a12880e63020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 41 validated image filenames belonging to 2 classes.\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 136ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix and Classification Report\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "print(\"\\nTest Set Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nTest Set Classification Report:\")\n",
        "print(classification_report(test_labels, test_preds, target_names=['Normal', 'Scol']))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Scol'], yticklabels=['Normal', 'Scol'])\n",
        "plt.title(\"Test Set Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "05Wi8vUAT6SD",
        "outputId": "549cc4e9-3dc0-4d22-ecf0-f9965cb660c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Set Confusion Matrix:\n",
            "[[11  1]\n",
            " [ 0 29]]\n",
            "\n",
            "Test Set Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       1.00      0.92      0.96        12\n",
            "        Scol       0.97      1.00      0.98        29\n",
            "\n",
            "    accuracy                           0.98        41\n",
            "   macro avg       0.98      0.96      0.97        41\n",
            "weighted avg       0.98      0.98      0.98        41\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}